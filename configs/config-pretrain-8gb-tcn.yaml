batch_size: 32 #64 batch size won't fit on 8 gb cards!
accumulate_grad_batches: 1 # For stock optimizer step
#accumulate_grad_batches_custom: 8 # For custom optimizer step on SimSiam
optimizer: sgd
learning_rate: 0.00375 #0.0075 @ 64 = 0.00375 @ 32
weight_decay: 0.0005
lars_wrapper: False
temperature: 0.1
architecture: simsiam
backbone: resnet50
hidden_mlp: 512
feat_dim: 2048
input_height: 224
tuple_length: 2
frame_offset: 1
tuple_offset: 1
patience: 10
max_epoch: 25
image_size: 224
exp_name: pretrain_224_tcn
gpus: 1
num_workers: 16
seed: None
precision: 16
early_stop_metric: val_accuracy
shared_transform: False
crop_scale_min: 0.2
crop_scale_max: 1.0
crop_ratio_min: 0.75
crop_ratio_max: 1.33
crop_strategy: bbox
sync_hflip: True
jitter_strength: 0.5
pairing_strategy: tcn_triplet
loss_function: triplet
